{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc3cd136-dcda-4175-9542-a823f4929f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Donchian Channel Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a9a0a5-9e0c-4618-b939-58a30df35c13",
   "metadata": {},
   "source": [
    "### Understanding the Donchian Channel Strategy\n",
    "As mentioned in the previous section of this article, the Donchian Channel Strategy is a fairly simple technical trading strategy that utilizes a visual indicator called Donchian Channels, named after its creator - Richard Donchian, to identify potential breakouts and trend reversals in asset prices.\n",
    "\n",
    "The Donchian Channels consist of three lines:\n",
    "\n",
    "- Upper Band — It is the highest price of an asset over a specified period.\n",
    "- Lower Band — It is the lowest price of an asset over a specified period.\n",
    "- Middle Band — It is the average of the lower and the upper band.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c975868-c6f5-4796-93bb-e83183bbb2ce",
   "metadata": {},
   "source": [
    "We will generate a buy signal when the close price or the day’s low is equal to the asset’s lowest price in the past 20 days. Conversely, we will generate a sell signal when the close price or the day’s high is equal to the asset’s highest price in the past 20 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a33d600-8d3c-476e-974c-e0f79301f4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q yfinance pandas_ta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b9a585b-6748-4279-996c-525b536bb8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas_ta as ta\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58f7e3b2-43f4-4230-886c-8a5ddba33556",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = yf.download(f'hcltech.ns', period='10y', progress=False)\n",
    "data[['low', 'mid', 'high']] = data.ta.donchian(lower_length=20, upper_length=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d44457eb-142d-4974-928a-6676622a1311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>low</th>\n",
       "      <th>mid</th>\n",
       "      <th>high</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-01-27</th>\n",
       "      <td>352.500000</td>\n",
       "      <td>357.387512</td>\n",
       "      <td>349.149994</td>\n",
       "      <td>356.125000</td>\n",
       "      <td>278.004730</td>\n",
       "      <td>6256364</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-28</th>\n",
       "      <td>354.750000</td>\n",
       "      <td>356.512512</td>\n",
       "      <td>349.524994</td>\n",
       "      <td>353.112488</td>\n",
       "      <td>275.653015</td>\n",
       "      <td>3914664</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-29</th>\n",
       "      <td>352.750000</td>\n",
       "      <td>358.750000</td>\n",
       "      <td>351.524994</td>\n",
       "      <td>355.575012</td>\n",
       "      <td>277.575287</td>\n",
       "      <td>2616276</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-30</th>\n",
       "      <td>355.725006</td>\n",
       "      <td>361.250000</td>\n",
       "      <td>351.950012</td>\n",
       "      <td>358.549988</td>\n",
       "      <td>279.897827</td>\n",
       "      <td>5446576</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-31</th>\n",
       "      <td>359.024994</td>\n",
       "      <td>367.475006</td>\n",
       "      <td>357.524994</td>\n",
       "      <td>365.549988</td>\n",
       "      <td>285.362152</td>\n",
       "      <td>3797684</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-19</th>\n",
       "      <td>1570.000000</td>\n",
       "      <td>1590.000000</td>\n",
       "      <td>1558.050049</td>\n",
       "      <td>1567.949951</td>\n",
       "      <td>1567.949951</td>\n",
       "      <td>2374099</td>\n",
       "      <td>1417.150024</td>\n",
       "      <td>1518.375</td>\n",
       "      <td>1619.599976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-22</th>\n",
       "      <td>1567.949951</td>\n",
       "      <td>1567.949951</td>\n",
       "      <td>1567.949951</td>\n",
       "      <td>1567.949951</td>\n",
       "      <td>1567.949951</td>\n",
       "      <td>0</td>\n",
       "      <td>1417.150024</td>\n",
       "      <td>1518.375</td>\n",
       "      <td>1619.599976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-23</th>\n",
       "      <td>1558.900024</td>\n",
       "      <td>1567.900024</td>\n",
       "      <td>1517.050049</td>\n",
       "      <td>1523.650024</td>\n",
       "      <td>1523.650024</td>\n",
       "      <td>3196630</td>\n",
       "      <td>1417.150024</td>\n",
       "      <td>1518.375</td>\n",
       "      <td>1619.599976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-24</th>\n",
       "      <td>1530.099976</td>\n",
       "      <td>1581.199951</td>\n",
       "      <td>1523.699951</td>\n",
       "      <td>1576.400024</td>\n",
       "      <td>1576.400024</td>\n",
       "      <td>2136023</td>\n",
       "      <td>1417.150024</td>\n",
       "      <td>1518.375</td>\n",
       "      <td>1619.599976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-25</th>\n",
       "      <td>1570.000000</td>\n",
       "      <td>1570.000000</td>\n",
       "      <td>1536.750000</td>\n",
       "      <td>1550.250000</td>\n",
       "      <td>1550.250000</td>\n",
       "      <td>2641656</td>\n",
       "      <td>1417.150024</td>\n",
       "      <td>1518.375</td>\n",
       "      <td>1619.599976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2466 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Open         High          Low        Close    Adj Close  \\\n",
       "Date                                                                          \n",
       "2014-01-27   352.500000   357.387512   349.149994   356.125000   278.004730   \n",
       "2014-01-28   354.750000   356.512512   349.524994   353.112488   275.653015   \n",
       "2014-01-29   352.750000   358.750000   351.524994   355.575012   277.575287   \n",
       "2014-01-30   355.725006   361.250000   351.950012   358.549988   279.897827   \n",
       "2014-01-31   359.024994   367.475006   357.524994   365.549988   285.362152   \n",
       "...                 ...          ...          ...          ...          ...   \n",
       "2024-01-19  1570.000000  1590.000000  1558.050049  1567.949951  1567.949951   \n",
       "2024-01-22  1567.949951  1567.949951  1567.949951  1567.949951  1567.949951   \n",
       "2024-01-23  1558.900024  1567.900024  1517.050049  1523.650024  1523.650024   \n",
       "2024-01-24  1530.099976  1581.199951  1523.699951  1576.400024  1576.400024   \n",
       "2024-01-25  1570.000000  1570.000000  1536.750000  1550.250000  1550.250000   \n",
       "\n",
       "             Volume          low       mid         high  \n",
       "Date                                                     \n",
       "2014-01-27  6256364          NaN       NaN          NaN  \n",
       "2014-01-28  3914664          NaN       NaN          NaN  \n",
       "2014-01-29  2616276          NaN       NaN          NaN  \n",
       "2014-01-30  5446576          NaN       NaN          NaN  \n",
       "2014-01-31  3797684          NaN       NaN          NaN  \n",
       "...             ...          ...       ...          ...  \n",
       "2024-01-19  2374099  1417.150024  1518.375  1619.599976  \n",
       "2024-01-22        0  1417.150024  1518.375  1619.599976  \n",
       "2024-01-23  3196630  1417.150024  1518.375  1619.599976  \n",
       "2024-01-24  2136023  1417.150024  1518.375  1619.599976  \n",
       "2024-01-25  2641656  1417.150024  1518.375  1619.599976  \n",
       "\n",
       "[2466 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dade02-1ef4-452d-bb48-2765de67bced",
   "metadata": {},
   "source": [
    "```if the day’s low or the close price of the stock is equal to the lower band of the Donchian channel and assign it to a column in the data frame. When this condition is true, we have to initiate a trade and buy the stock the very next day. This will serve as the buy signal.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f527e23-a525-4de9-bdff-e99167604c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LONG\n",
    "data['long'] = ((data['Close']==data['low'])|(data['Low']==data['low'])).astype('int')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8baf9cf8-0552-4835-a3fd-ff9901227bcc",
   "metadata": {},
   "source": [
    "```if the day’s high or the close price of the stock is equal to the upper band of the Donchian channel and assign it to a column in the data frame. When this condition is true, we should close any open trade the very next day. This will serve as the sell signal.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32214ddf-0913-4182-8b96-0fa0c9beda4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SHORT\n",
    "data['short'] = ((data['Close']==data['high'])|(data['High']==data['high'])).astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47b580f5-af7a-407d-958a-ec0b1ab7fe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trade_donchian(row):\n",
    "    global trades, trade_open\n",
    "    row = row.to_dict()\n",
    "\n",
    "    if((trade_open==True) and (row['long'] == 1)): pass\n",
    "\n",
    "    elif((trade_open==False) and (row['short'] == 1)): pass\n",
    "\n",
    "    elif((trade_open==False) and (row['long'] == 1)):\n",
    "        # open trade\n",
    "        trade_open = True\n",
    "        _trade = {\n",
    "            'buy_date': row['next_date'],\n",
    "            'buy_price': round(row['next_day_open_price']*1.005,2),\n",
    "            'sell_price': None,\n",
    "            'sell_date': None,\n",
    "        }\n",
    "        trades.append(_trade)\n",
    "        del _trade\n",
    "\n",
    "    elif((trade_open==True) and (row['short'] == 1)):\n",
    "        # close trade\n",
    "        trade_open = False\n",
    "        _trade = trades[-1]\n",
    "        _trade['sell_date'] = row['next_date']\n",
    "        _trade['sell_price'] = round(row['next_day_open_price']*0.995,2)\n",
    "        trades[-1] = _trade\n",
    "        del _trade\n",
    "\n",
    "\n",
    "\n",
    "def backtest(stock, period, low=20, high=20):\n",
    "    global trades, trade_open\n",
    "    \n",
    "    # get the stock prices\n",
    "    data = yf.download(f'{stock}.ns', period=period, progress=False)\n",
    "    \n",
    "    data = data.reset_index()\n",
    "    \n",
    "    # calculate donchian channels\n",
    "    data[['low', 'mid', 'high']] = data.ta.donchian(lower_length=low, upper_length=high)\n",
    "    \n",
    "    # implement the trading strategy\n",
    "    data['long'] = ((data['Close']==data['low'])|(data['Low']==data['low'])).astype('int')\n",
    "    data['short'] = ((data['Close']==data['high'])|(data['High']==data['high'])).astype('int')\n",
    "     \n",
    "    # get the next day open price and date\n",
    "    data['next_day_open_price'] = data['Open'].shift(-1)\n",
    "    data['next_date'] = data['Date'].shift(-1).astype('string')\n",
    "    \n",
    "    trade_open = False\n",
    "    trades = []\n",
    "    data.dropna(inplace=True)\n",
    "    \n",
    "    cols = ['Date', 'Open', 'Close', 'Adj Close', 'Low', 'High', \n",
    "            'low', 'mid', 'high', 'long', 'short', 'next_day_open_price', \n",
    "            'next_date']\n",
    "\n",
    "    data = data[cols]\n",
    "\n",
    "    data.apply(trade_donchian, axis=1)\n",
    "\n",
    "    if(len(trades)==0): return None\n",
    "\n",
    "    x = pd.DataFrame(trades)\n",
    "    \n",
    "    # calculate the returns and holding period\n",
    "    x['buy_date'] = pd.to_datetime(x['buy_date'], format=\"%Y-%m-%d\", dayfirst=True)\n",
    "    x['sell_date'] = pd.to_datetime(x['sell_date'], format=\"%Y-%m-%d\", dayfirst=True)\n",
    "    x['returns'] = round(100*(x['sell_price']-x['buy_price'])/x['buy_price'],2)\n",
    "    x['holding_period'] = (x['sell_date'] - x['buy_date']).dt.days\n",
    "    x['stock'] = stock\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "TRADES = pd.DataFrame()\n",
    "trades = []\n",
    "trade_open = False\n",
    "\n",
    "nifty_50_stocks = ['EICHERMOT','HEROMOTOCO','NESTLEIND','ONGC',\n",
    "                   'BAJAJ-AUTO','TATASTEEL','GRASIM',\n",
    "                   'BRITANNIA','BAJFINANCE','M&M','divislab',\n",
    "                   'HINDUNILVR','HDFCBANK','HDFCLIFE','BHARTIARTL','TCS',\n",
    "                   'LT','DRREDDY','ULTRACEMCO','SUNPHARMA','NTPC',\n",
    "                   'TATAMOTORS','UPL','SBIN','HINDALCO','ITC','JSWSTEEL',\n",
    "                   'COALINDIA','RELIANCE','BPCL','LTIM','MARUTI','HCLTECH',\n",
    "                   'POWERGRID','WIPRO','SBILIFE','AXISBANK',\n",
    "                   'ADANIPORTS','ICICIBANK','TITAN','BAJAJFINSV','KOTAKBANK',\n",
    "                   'TATACONSUM','APOLLOHOSP','INFY','ASIANPAINT',\n",
    "                   'ADANIENT','INDUSINDBK','TECHM','CIPLA']\n",
    "\n",
    "\n",
    "for stock in nifty_50_stocks:\n",
    "    _tr = backtest(stock, '10y', 20, 20)\n",
    "    if(len(TRADES)==0): TRADES = _tr\n",
    "    else: TRADES = pd.concat([TRADES, _tr], ignore_index=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de9e5902-658b-415b-894c-c26ccc9c2306",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pos_neg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpos_neg\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pos_neg' is not defined"
     ]
    }
   ],
   "source": [
    "ref: https://python.plainenglish.io/generating-swing-trading-signals-using-donchian-strategy-in-python-7aff3c9ce0a8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54c24b7-2fc0-4986-b067-91515e1d8bcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42f5b7c3-9792-4c4a-b523-728594552393",
   "metadata": {},
   "source": [
    "## Creating a Momentum Trading Scanner with Dynamic Time Warping\n",
    "https://freedium.cfd/https://medium.datadriveninvestor.com/creating-a-momentum-trading-scanner-with-dynamic-time-warping-2a4e7ceb1e1c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7c9d73b-30a0-40df-b080-03e1ce5b6f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numba\n",
      "  Downloading numba-0.58.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting llvmlite<0.42,>=0.41.0dev0 (from numba)\n",
      "  Downloading llvmlite-0.41.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: numpy<1.27,>=1.22 in /home/tikam/stock-market/env3/lib/python3.10/site-packages (from numba) (1.26.2)\n",
      "Downloading numba-0.58.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hDownloading llvmlite-0.41.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hInstalling collected packages: llvmlite, numba\n",
      "Successfully installed llvmlite-0.41.1 numba-0.58.1\n"
     ]
    }
   ],
   "source": [
    "!pip install numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c235db3-d42e-493f-a7ff-96a1615762fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'TSLA.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 310\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 310\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTSLA.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m     t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    314\u001b[0m     candidates \u001b[38;5;241m=\u001b[39m run_scanner(\n\u001b[1;32m    315\u001b[0m         df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClose\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[1;32m    316\u001b[0m         nb\u001b[38;5;241m.\u001b[39mtyped\u001b[38;5;241m.\u001b[39mList(load_breakout_examples()),\n\u001b[1;32m    317\u001b[0m         LENGTH,\n\u001b[1;32m    318\u001b[0m         THRESHOLD,\n\u001b[1;32m    319\u001b[0m     )\n",
      "File \u001b[0;32m~/stock-market/env3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/stock-market/env3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/stock-market/env3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/stock-market/env3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/stock-market/env3/lib/python3.10/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'TSLA.csv'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numba as nb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "import plotly.io as pio\n",
    "import plotly.graph_objects as go\n",
    "pio.renderers.default = 'browser'\n",
    "\n",
    "# Breakout examples in the format [ticker, start date, end date]\n",
    "BREAKOUTS = [\n",
    "    ['MNKD', '2020-11-03', '2020-12-10'],\n",
    "    ['MNKD', '2013-02-27', '2013-03-28'],\n",
    "    ['LPI', '2021-05-11', '2021-06-18'],\n",
    "    ['AMD', '2021-07-15', '2021-10-12'],\n",
    "    ['AMD', '2019-10-03', '2019-12-11'],\n",
    "    ['AMD', '2018-04-30', '2018-07-25'],\n",
    "    ['NVAX', '2020-03-12', '2020-05-08'],\n",
    "    ['LEU', '2021-08-25', '2021-10-08'],\n",
    "    ['LEU', '2020-11-18', '2020-12-11'],\n",
    "    ['LEU', '2020-05-06', '2020-05-29'],\n",
    "    ['FUTU', '2020-04-29', '2020-06-12'],\n",
    "    ['LAC', '2021-08-18', '2021-10-11'],\n",
    "    ['LAC', '2020-07-16', '2020-09-11'],\n",
    "]\n",
    "\n",
    "# This says we are going to compare a time-series of length LENGTH to all the\n",
    "# breakout examples (which could be longer or shorter)\n",
    "LENGTH = 35\n",
    "\n",
    "# Upper DTW cost threshold to be considered as a breakout candidate\n",
    "THRESHOLD = 12.23\n",
    "\n",
    "# Upper and lower dates limits for the plot\n",
    "PLOT_LOWER_DATE = '2019-10-01'\n",
    "PLOT_UPPER_DATE = '2020-10-01'\n",
    "\n",
    "\n",
    "@nb.jit(nopython = True)\n",
    "def get_cost_matrix(ts1: np.array, ts2: np.array) -> np.array:\n",
    "    '''\n",
    "    Get the dynamic time warping cost matrix, which is used to determine\n",
    "    the warping path and hence the overall cost of the path.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ts1 : np.array\n",
    "        The first time series to compare.\n",
    "    ts2 : np.array\n",
    "        The second time series to compare.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    C : np.array\n",
    "        The dynamic time warping cost matrix.\n",
    "    '''\n",
    "    \n",
    "    # Initialise a full cost matrix, filled with np.inf. This is so we can\n",
    "    # start the algorithm and not get stuck on the boundary\n",
    "    C = np.full(\n",
    "        shape = (ts1.shape[0] + 1, ts2.shape[0] + 1), \n",
    "        fill_value = np.inf,\n",
    "    )\n",
    "    \n",
    "    # Place the corner to zero, so that we don't have the minimum of 3 infs\n",
    "    C[0, 0] = 0\n",
    "    \n",
    "    for i in range(1, ts1.shape[0] + 1):\n",
    "        for j in range(1, ts2.shape[0] + 1):\n",
    "            \n",
    "            # Euclidian distance between the two points\n",
    "            dist = abs(ts1[i-1] - ts2[j-1])\n",
    "            \n",
    "            # Find the cheapest cost of all three neighbours\n",
    "            prev_min = min(C[i-1, j], C[i, j-1], C[i-1, j-1])\n",
    "            \n",
    "            # Populate the entry in the cost matrix\n",
    "            C[i, j] = dist + prev_min\n",
    "            \n",
    "    return C[1:, 1:]\n",
    "\n",
    "\n",
    "@nb.jit(nopython = True)\n",
    "def get_path_cost(C: np.array) -> Tuple[list, float]:\n",
    "    '''\n",
    "    Get the optimal path and overall cost of the path.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    C : np.array\n",
    "        The DTW cost matrix.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    path, cost : Tuple[list, float]\n",
    "        The optimal path coordinates and the overall cost.\n",
    "    '''\n",
    "    \n",
    "    i = C.shape[0] - 1\n",
    "    j = C.shape[1] - 1\n",
    "    \n",
    "    path = [[i, j]]\n",
    "\n",
    "    while (i > 0) | (j > 0):\n",
    "        \n",
    "        min_cost = min(C[i-1, j-1], C[i-1, j], C[i, j-1])\n",
    "        \n",
    "        if min_cost == C[i-1, j-1]:\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "        elif min_cost == C[i-1, j]:\n",
    "            i -= 1\n",
    "        elif min_cost == C[i, j-1]:\n",
    "            j -= 1\n",
    "        \n",
    "        path.append([i, j])\n",
    "        \n",
    "    return path, C[-1, -1]\n",
    "\n",
    "\n",
    "@nb.jit(nopython = True)\n",
    "def standard_scale(ts: np.array) -> np.array:\n",
    "    return (ts - np.mean(ts))/np.std(ts)\n",
    "\n",
    "\n",
    "def get_time_series(df: pd.DataFrame,\n",
    "                    date_start: str,\n",
    "                    date_end: str) -> np.array:\n",
    "    '''\n",
    "    Filter the price dataframe to the specified range, and scale using a z\n",
    "    score scaling approach.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        The price dataframe.\n",
    "    date_start : str\n",
    "        Starting date for the time series in the format yyyy-mm-dd\n",
    "    date_end : str\n",
    "        Ending date for the time series in the format yyyy-mm-dd\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.array\n",
    "        The scaled time series\n",
    "    '''\n",
    "    \n",
    "    df = df[\n",
    "        (df['Date'] >= date_start)\n",
    "        & (df['Date'] <= date_end)        \n",
    "    ]\n",
    "    \n",
    "    return standard_scale(df['Close'].values)\n",
    "\n",
    "\n",
    "@nb.jit(nopython = True)\n",
    "def get_avg_cost(ts: np.array, breakouts: list) -> float:\n",
    "    '''\n",
    "    Compare the time series with all the breakout examples, and return the\n",
    "    mean of all costs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ts : np.array\n",
    "        The time series we are comparing.\n",
    "    breakouts : list\n",
    "        A list of time series with the breakout examples.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The mean of all costs from the time series comparisons.\n",
    "    '''\n",
    "    \n",
    "    costs = []\n",
    "    \n",
    "    for i in range(len(breakouts)):\n",
    "        C = get_cost_matrix(ts, breakouts[i])\n",
    "        _, path_cost = get_path_cost(C.astype(np.float64))\n",
    "        \n",
    "        costs.append(path_cost)\n",
    "            \n",
    "    return np.mean(np.array(costs))\n",
    "\n",
    "\n",
    "def load_breakout_examples() -> list:\n",
    "    '''\n",
    "    Load all breakout examples for the time-series comparisons\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        A list of scaled time series for comaprisons\n",
    "    '''\n",
    "    \n",
    "    breakouts = []\n",
    "    \n",
    "    for b in BREAKOUTS:\n",
    "         \n",
    "        df = pd.read_csv(f'data/{b[0]}.csv')\n",
    "        breakouts.append(get_time_series(df, b[1], b[2]))\n",
    "    \n",
    "    return breakouts\n",
    "\n",
    "\n",
    "@nb.jit(nopython = True)\n",
    "def run_scanner(close: np.array, \n",
    "                breakouts: list,\n",
    "                length: int,\n",
    "                threshold: float) -> np.array:\n",
    "    '''\n",
    "    Run the scanner over the entire of the stock history, and return an array\n",
    "    to indicate whether the region is a breakout candidate (1) or not (0)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    close : np.array\n",
    "        The stock closing prices.\n",
    "    breakouts : list\n",
    "        A list of time series with the breakout examples.\n",
    "    length : int\n",
    "        The lookback period for the scanner.\n",
    "    threshold : float\n",
    "        The scanner threshold (values less than this are considered a breakout) \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.array\n",
    "        A binary array indicating the positions where the scanner returns a\n",
    "        positive result.\n",
    "    '''\n",
    "    \n",
    "    candidates = []\n",
    "    for idx in range(length, close.shape[0]):\n",
    "        \n",
    "        ts = standard_scale(close[idx-length:idx])\n",
    "        \n",
    "        cost = get_avg_cost(ts, breakouts)\n",
    "        \n",
    "        if cost < threshold:\n",
    "            candidates.append(1)\n",
    "        else:\n",
    "            candidates.append(0)\n",
    "            \n",
    "    return np.array(candidates)\n",
    "\n",
    "\n",
    "def plot_result(df: pd.DataFrame):\n",
    "    \n",
    "    df = df[\n",
    "        (df['Date'] >= PLOT_LOWER_DATE)\n",
    "        & (df['Date'] <= PLOT_UPPER_DATE)\n",
    "    ]\n",
    "    \n",
    "    df = df.reset_index(drop = True)\n",
    "    \n",
    "    df.loc[:, 'breakout_region'] = np.where(\n",
    "        df['filtered'],\n",
    "        df['High'].max(),\n",
    "        df['Low'].min(),\n",
    "    )\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Candlestick(\n",
    "            x = df['Date'],\n",
    "            open = df['Open'],\n",
    "            high = df['High'],\n",
    "            low = df['Low'],\n",
    "            close = df['Close'],\n",
    "            showlegend = False,        \n",
    "        ),\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x = df['Date'], \n",
    "            y = df['breakout_region'],\n",
    "            fill = 'tonexty',\n",
    "            fillcolor = 'rgba(0, 236, 109, 0.2)',\n",
    "            mode = 'lines',\n",
    "            line = {'width': 0, 'shape': 'hvh'},\n",
    "            showlegend = False,\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        xaxis = {'title': 'Date'},\n",
    "        yaxis = {'range': [df['Low'].min(), df['High'].max()], 'title': 'Price ($)'},\n",
    "        title = 'TSLA - Breakout Candidates',\n",
    "        width = 700,\n",
    "        height = 700,\n",
    "    )\n",
    "    \n",
    "    fig.update_xaxes(\n",
    "        rangebreaks = [{'bounds': ['sat', 'mon']}],\n",
    "        rangeslider_visible = False,\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    df = pd.read_csv('TSLA.csv')\n",
    "    \n",
    "    t0 = time.time()\n",
    "    \n",
    "    candidates = run_scanner(\n",
    "        df['Close'].values,\n",
    "        nb.typed.List(load_breakout_examples()),\n",
    "        LENGTH,\n",
    "        THRESHOLD,\n",
    "    )\n",
    "    \n",
    "    df = df[LENGTH:].reset_index(drop = True)\n",
    "    df.loc[:, 'filtered'] = candidates\n",
    "    \n",
    "    print('Number of scans performed:', len(df) - LENGTH)\n",
    "    print('Time taken:', time.time() - t0)\n",
    "    \n",
    "    plot_result(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfba026-d2dd-4988-b622-d98c664e74a0",
   "metadata": {},
   "source": [
    "###  the technicals that I use the most are:\n",
    "\n",
    "For Trend: 50 and 200 day moving averages\n",
    "For Momentum: Relative Strength Index\n",
    "For Swings: MACD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9374cb-5fd1-44c1-b262-3e62f4992e70",
   "metadata": {},
   "source": [
    "ref - gui - https://freedium.cfd/https://medium.com/quant-factory/increase-your-profits-by-50-with-a-simple-yet-elegant-stock-screener-bf63b71512b5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17029fe0-c377-4e3c-a9d9-922e999729a0",
   "metadata": {},
   "source": [
    "# best books\n",
    "https://zodiactrading.medium.com/top-10-must-read-books-for-mastering-technical-analysis-4942ff9a231a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30f737b-f234-41d2-92c8-0ebdf731aecd",
   "metadata": {},
   "source": [
    "## Try on 29 jan\n",
    "\n",
    "- https://github.com/je-suis-tm/quant-trading\n",
    "- https://towardsdatascience.com/building-a-comprehensive-set-of-technical-indicators-in-python-for-quantitative-trading-8d98751b5fb\n",
    "- http://webcache.googleusercontent.com/search?q=cache:https://medium.datadriveninvestor.com/unlocking-profit-building-a-winning-pair-trading-strategy-in-python-cfc8cc30b98a&strip=0&vwsrc=1&referer=medium-parser\n",
    "- https://readmedium.com/an-algo-trading-strategy-which-made-8-371-a-python-case-study-58ed12a492dc\n",
    "- https://readmedium.com/en/https:/medium.com/@redeaddiscolll/quantitative-trading-strategies-algorithmic-trading-712f703ed16b\n",
    "- https://github.com/neurotrader888/TechnicalAnalysisAutomation/tree/main\n",
    "- https://github.com/gianlucamalato/machinelearning/tree/master\n",
    "- https://github.com/LastAncientOne/Stock_Analysis_For_Quant/tree/master/Python_Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c36c84-b9ac-4653-8e0d-f111e288e8fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
