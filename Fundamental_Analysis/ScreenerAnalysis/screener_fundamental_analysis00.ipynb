{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31f37f1-038a-4c74-b1f4-0d13c37f8c37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a54761cf-3544-4909-be7e-27cab8d5e80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File for ITC downloaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def download_excel(company_name):\n",
    "    # Construct the correct URL based on the website's structure\n",
    "    url = f\"https://www.screener.in/company/{company_name}/\"\n",
    "\n",
    "    # Replace this payload with the actual csrfmiddlewaretoken value\n",
    "    payload = {\n",
    "        'csrfmiddlewaretoken': 'cmfHDrRznDB5CXAGVFcQ4bHnWXdSEg3jCZWQJ3TRweOLkn1EcHI6r3RvcOWUMcLp',\n",
    "        'next': f'/company/{company_name}/consolidated/'\n",
    "    }\n",
    "\n",
    "    # Replace this with the actual cookie value\n",
    "    cookies = {\n",
    "        'csrftoken': 'ANRjgMcsjLnQSAB8rcGqx2kiq1Tci6Sg',\n",
    "        'sessionid': 'gsblyiotrq9442ka3t5vo75c9so0lm63'\n",
    "    }\n",
    "\n",
    "    # Replace this with the actual user-agent value\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',\n",
    "        'Content-Type': 'application/x-www-form-urlencoded',\n",
    "        'Referer': f'https://www.screener.in/company/{company_name}/consolidated/',  # Add the referer URL here\n",
    "    }\n",
    "\n",
    "    # Send the POST request\n",
    "    response = requests.post(url, data=payload, headers=headers, cookies=cookies)\n",
    "\n",
    "    # Check if the request was successful (Status Code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Save the content of the response to a file\n",
    "        with open(f'{company_name}.xlsx', 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"File for {company_name} downloaded successfully.\")\n",
    "    else:\n",
    "        print(f\"Error for {company_name}: {response.status_code} - {response.text}\")\n",
    "\n",
    "# Example usage:\n",
    "company_name = \"ITC\"  # Replace this with the desired company name\n",
    "download_excel(company_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68913311-d38b-4086-ae86-7141a54b421c",
   "metadata": {},
   "source": [
    "## Download multiple stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66e79aec-65c3-4ddb-b274-2a5a389e55b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File for IOC downloaded successfully.\n",
      "Proceeding to the next stock...\n",
      "File for HSCL downloaded successfully.\n",
      "Proceeding to the next stock...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "def download_excel(company_name):\n",
    "    # Construct the correct URL based on the website's structure\n",
    "    url = f\"https://www.screener.in/company/{company_name}/\"\n",
    "\n",
    "    # Replace this payload with the actual csrfmiddlewaretoken value\n",
    "    payload = {\n",
    "        'csrfmiddlewaretoken': 'cmfHDrRznDB5CXAGVFcQ4bHnWXdSEg3jCZWQJ3TRweOLkn1EcHI6r3RvcOWUMcLp',\n",
    "        'next': f'/company/{company_name}/consolidated/'\n",
    "    }\n",
    "\n",
    "    # Replace this with the actual cookie value\n",
    "    cookies = {\n",
    "        'csrftoken': 'ANRjgMcsjLnQSAB8rcGqx2kiq1Tci6Sg',\n",
    "        'sessionid': 'gsblyiotrq9442ka3t5vo75c9so0lm63'\n",
    "    }\n",
    "\n",
    "    # Replace this with the actual user-agent value\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',\n",
    "        'Content-Type': 'application/x-www-form-urlencoded',\n",
    "        'Referer': f'https://www.screener.in/company/{company_name}/consolidated/',  # Add the referer URL here\n",
    "    }\n",
    "\n",
    "    # Send the POST request\n",
    "    response = requests.post(url, data=payload, headers=headers, cookies=cookies)\n",
    "\n",
    "    # Check if the request was successful (Status Code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Save the content of the response to a file\n",
    "        with open(f'{company_name}.xlsx', 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"File for {company_name} downloaded successfully.\")\n",
    "        return True  # Signal that the file was downloaded successfully\n",
    "    else:\n",
    "        print(f\"Error for {company_name}: {response.status_code} - {response.text}\")\n",
    "        return False  # Signal that there was an error downloading the file\n",
    "\n",
    "# Example usage:\n",
    "stock_list = [\"IOC\",\"HSCL\"]\n",
    "\n",
    "for stock in stock_list:\n",
    "    download_path = \"./data\"\n",
    "    file_downloaded = download_excel(stock)\n",
    "\n",
    "    # If file was downloaded successfully, proceed with the next stock\n",
    "    if file_downloaded:\n",
    "        print(f\"Proceeding to the next stock...\")\n",
    "    else:\n",
    "        print(f\"Skipping to the next stock due to the error.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "319c3084-15a4-4a12-9372-969a858e4e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 1 converted to CSV: table_1.csv\n",
      "Table 2 converted to CSV: table_2.csv\n",
      "Table 3 converted to CSV: table_3.csv\n",
      "Table 4 converted to CSV: table_4.csv\n",
      "Table 5 converted to CSV: table_5.csv\n",
      "Table 6 converted to CSV: table_6.csv\n",
      "Table 7 converted to CSV: table_7.csv\n",
      "Table 8 converted to CSV: table_8.csv\n",
      "Table 9 converted to CSV: table_9.csv\n",
      "Table 10 converted to CSV: table_10.csv\n",
      "Table 11 converted to CSV: table_11.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Load HTML content from the file\n",
    "with open('ITC.xlsx', 'r', encoding='utf-8') as html_file:\n",
    "    html_content = html_file.read()\n",
    "\n",
    "# Parse HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Find all tables in the HTML\n",
    "tables = soup.find_all('table')\n",
    "\n",
    "# Iterate through each table and convert it to CSV\n",
    "for i, table in enumerate(tables, start=1):\n",
    "    # Convert the table to a DataFrame\n",
    "    df = pd.read_html(str(table), flavor='bs4')[0]\n",
    "\n",
    "    # Save DataFrame to a CSV file\n",
    "    csv_file_path = f'table_{i}.csv'\n",
    "    df.to_csv(csv_file_path, index=False, encoding='utf-8')\n",
    "\n",
    "    print(f'Table {i} converted to CSV: {csv_file_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b291139-dee1-47f9-bd89-491375f6691b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 1 (Peer comparison) converted to CSV: Peer comparison.csv\n",
      "Table 2 (Quarterly Results) converted to CSV: Quarterly Results.csv\n",
      "Table 3 (Profit & Loss) converted to CSV: Profit & Loss.csv\n",
      "Table 4 (Balance Sheet) converted to CSV: Balance Sheet.csv\n",
      "Table 5 (Cash Flows) converted to CSV: Cash Flows.csv\n",
      "Table 6 (Ratios) converted to CSV: Ratios.csv\n",
      "Table 7 (Shareholding Pattern) converted to CSV: Shareholding Pattern.csv\n",
      "No table found for Documents\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def convert_html_to_csv(file_path):\n",
    "    # Load HTML content from the file\n",
    "    with open(file_path, 'r', encoding='utf-8') as html_file:\n",
    "        html_content = html_file.read()\n",
    "\n",
    "    # Parse HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Find all h2 elements in the HTML\n",
    "    h2_elements = soup.find_all('h2')\n",
    "\n",
    "    # Iterate through each h2 element and convert the corresponding table to CSV\n",
    "    for i, h2 in enumerate(h2_elements, start=1):\n",
    "        # Extract the table name from the h2 element\n",
    "        table_name = h2.get_text(strip=True)\n",
    "\n",
    "        # Find the corresponding table following the h2 element\n",
    "        table = h2.find_next('table')\n",
    "\n",
    "        # Check if a table was found\n",
    "        if table:\n",
    "            # Convert the table to a DataFrame\n",
    "            df = pd.read_html(str(table), flavor='bs4')[0]\n",
    "\n",
    "            # Define CSV file name based on the extracted table name\n",
    "            csv_file_path = f'{table_name}.csv'\n",
    "\n",
    "            # Save DataFrame to a CSV file\n",
    "            df.to_csv(csv_file_path, index=False, encoding='utf-8')\n",
    "\n",
    "            print(f'Table {i} ({table_name}) converted to CSV: {csv_file_path}')\n",
    "        else:\n",
    "            print(f'No table found for {table_name}')\n",
    "\n",
    "# Example usage:\n",
    "convert_html_to_csv('ITC.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d74c48-0f4b-4e84-baae-87932da8ea58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
