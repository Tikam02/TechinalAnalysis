{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb4c77e0-f8b7-47fa-b514-35c5161ee7ca",
   "metadata": {},
   "source": [
    "# Screener 02\n",
    "\n",
    "https://readmedium.com/en/https:/wire.insiderfinance.io/identifying-breakout-stocks-with-python-a-data-driven-selection-guide-d8a3d1ba172e\n",
    "https://github.com/shashankvemuri/Finance/blob/master/find_stocks/get_rsi_tickers.py\n",
    "\n",
    "https://medium.com/@redeaddiscolll\n",
    "https://medium.com/@py.chin315\n",
    "https://github.com/peiyingchin/Medium/blob/main/Trading%20strategy%20with%2055%25%20win%20chance/Trading%20strategy%20with%2055%25%20win%20chance.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00beccde-3951-4426-a338-29a19777f853",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numba as nb\n",
    "import yfinance as yf\n",
    "\n",
    "@nb.jit(nopython = True)\n",
    "def explicit_heat_smooth(prices: np.array,\n",
    "                         t_end: float = 5.0) -> np.array:\n",
    "    '''\n",
    "    Smoothen out a time series using a explicit finite difference method.\n",
    "    Parameters\n",
    "    ----------\n",
    "    prices : np.array\n",
    "        The price to smoothen\n",
    "    t_end : float\n",
    "        The time at which to terminate the smootheing (i.e. t = 2)\n",
    "    Returns\n",
    "    -------\n",
    "    P : np.array\n",
    "        The smoothened time-series\n",
    "    '''\n",
    "    \n",
    "    k = 0.1 # Time spacing, must be < 1 for numerical stability\n",
    "    \n",
    "    # Set up the initial condition\n",
    "    P = prices\n",
    "    \n",
    "    t = 0\n",
    "    while t < t_end:\n",
    "        # Solve the finite difference scheme for the next time-step\n",
    "        P = k*(P[2:] + P[:-2]) + P[1:-1]*(1-2*k)\n",
    "        \n",
    "        # Add the fixed boundary conditions since the above solves the interior\n",
    "        # points only\n",
    "        P = np.hstack((\n",
    "            np.array([prices[0]]),\n",
    "            P,\n",
    "            np.array([prices[-1]]),\n",
    "        ))\n",
    "        t += k\n",
    "\n",
    "    return P\n",
    "\n",
    "        \n",
    "@nb.jit(nopython = True)\n",
    "def check_consolidation(prices: np.array,\n",
    "                        perc_change_days: int,\n",
    "                        perc_change_thresh: float,\n",
    "                        check_days: int) -> int:\n",
    "    '''\n",
    "    Smoothen the time-series and check for consolidation, see the\n",
    "    docstring of find_consolidation for the parameters\n",
    "    '''\n",
    "    \n",
    "    # Find the smoothed representation of the time series\n",
    "    prices = explicit_heat_smooth(prices)\n",
    "    \n",
    "    # Perc change of the smoothed time series to perc_change_days days prior\n",
    "    perc_change = prices[perc_change_days:]/prices[:-perc_change_days] - 1\n",
    "    \n",
    "    consolidating = np.where(np.abs(perc_change) < perc_change_thresh, 1, 0)\n",
    "    \n",
    "    # Provided one entry in the last n days passes the consolidation check,\n",
    "    # we say that the financial instrument is in consolidation on the end day\n",
    "    if np.sum(consolidating[-check_days:]) > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "@nb.jit(nopython = True)\n",
    "def find_consolidation(prices: np.array,\n",
    "                       days_to_smooth: int = 50,\n",
    "                       perc_change_days: int = 5,\n",
    "                       perc_change_thresh: float = 0.015,\n",
    "                       check_days: int = 5) -> np.array:\n",
    "    '''\n",
    "    Return a binary array to indicate whether each of the data-points are\n",
    "    classed as consolidating or not\n",
    "    Parameters\n",
    "    ----------\n",
    "    prices : np.array\n",
    "        The price time series to check for consolidation\n",
    "    days_to_smooth : int, optional\n",
    "        The length of the time-series to smoothen (days). The default is 50.\n",
    "    perc_change_days : int, optional\n",
    "        The days back to % change compare against (days). The default is 5.\n",
    "    perc_change_thresh : float, optional\n",
    "        The range trading % criteria for consolidation. The default is 0.015.\n",
    "    check_days : int, optional\n",
    "        This says the number of lookback days to check for any consolidation.\n",
    "        If any days in check_days back is consolidating, then the last data\n",
    "        point is said to be consolidating. The default is 5.\n",
    "    Returns\n",
    "    -------\n",
    "    res : np.array\n",
    "        The binary array indicating consolidation (1) or not (0)\n",
    "    '''\n",
    "    \n",
    "    res = np.full(prices.shape, np.nan)\n",
    "    \n",
    "    for idx in range(days_to_smooth, prices.shape[0]):\n",
    "        res[idx] = check_consolidation(\n",
    "            prices = prices[idx-days_to_smooth:idx],\n",
    "            perc_change_days = perc_change_days,\n",
    "            perc_change_thresh = perc_change_thresh,\n",
    "            check_days = check_days,\n",
    "        )\n",
    "        \n",
    "    return res\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    df = yf.download('TSLA').reset_index()\n",
    "    df.loc[:, 'consolidating'] = find_consolidation(df['Close'].values)\n",
    "    df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045c1995-0024-4a21-94a2-94dd113f4877",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = yf.download('TSLA').reset_index()\n",
    "df.loc[:, 'consolidating'] = find_consolidation(df['Close'].values)\n",
    "df.loc[:, 'trend_filter'] = trend_filter(df['Close'])\n",
    "df.loc[:, 'filtered'] = np.where(\n",
    "    df['consolidating'] + df['trend_filter'] == 2,\n",
    "    True,\n",
    "    False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37410db1-243b-4ee7-8b04-e89389d3b0ec",
   "metadata": {},
   "source": [
    "## RSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e7dd783-c120-4588-94bb-3ff8ddc3a575",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ta_functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m parent_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mgetcwd())\n\u001b[1;32m      7\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(parent_dir)\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mta_functions\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mta\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtickers\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mti\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Get dates for the past year\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ta_functions'"
     ]
    }
   ],
   "source": [
    "# Import Dependencies\n",
    "import datetime\n",
    "from pandas_datareader import data as pdr\n",
    "import sys\n",
    "import os\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "sys.path.append(parent_dir)\n",
    "import ta_functions as ta\n",
    "import tickers as ti\n",
    "\n",
    "# Get dates for the past year\n",
    "start_date = datetime.datetime.now() - datetime.timedelta(days=365)\n",
    "end_date = datetime.date.today()\n",
    "\n",
    "# Load list of S&P 500 tickers from tickers module\n",
    "tickers = ti.tickers_sp500()\n",
    "\n",
    "# Initialize lists for overbought and oversold tickers\n",
    "oversold_tickers = []\n",
    "overbought_tickers = []\n",
    "\n",
    "# Retrieve adjusted close prices for the tickers\n",
    "sp500_data = pdr.get_data_yahoo(tickers, start_date, end_date)['Adj Close']\n",
    "\n",
    "# Analyze each ticker for RSI\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        # Create a new DataFrame for the ticker\n",
    "        data = sp500_data[[ticker]].copy()\n",
    "\n",
    "        # Calculate the RSI for the ticker\n",
    "        data[\"rsi\"] = ta.RSI(data[ticker], timeperiod=14)\n",
    "\n",
    "        # Calculate the mean of the last 14 RSI values\n",
    "        mean_rsi = data[\"rsi\"].tail(14).mean()\n",
    "\n",
    "        # Print the RSI value\n",
    "        print(f'{ticker} has an RSI value of {round(mean_rsi, 2)}')\n",
    "\n",
    "        # Classify the ticker based on its RSI value\n",
    "        if mean_rsi <= 30:\n",
    "            oversold_tickers.append(ticker)\n",
    "        elif mean_rsi >= 70:\n",
    "            overbought_tickers.append(ticker)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'Error processing {ticker}: {e}')\n",
    "\n",
    "# Output the lists of oversold and overbought tickers\n",
    "print(f'Oversold tickers: {oversold_tickers}')\n",
    "print(f'Overbought tickers: {overbought_tickers}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aba17db-88ee-4f99-8b3e-4fdd73724d6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a3122e-a564-441d-8507-ac9ec679c3fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
